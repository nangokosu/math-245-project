step.model1 <- train(hapiscore_whr ~., data = df_variables_imputed,
method = "leapBackward",
tuneGrid = data.frame(nvmax = 1:21),
trControl = train.control)
set.seed(123)
# Set up repeated k-fold cross-validation
#Train the model
step.model1 <- train(hapiscore_whr ~., data = df_variables_imputed,
method = "leapBackward",
trControl = train.control)
set.seed(123)
# Set up repeated k-fold cross-validation
#Train the model
step.model1 <- train(hapiscore_whr ~., data = df_variables_full,
method = "leapBackward",
trControl = train.control,
tuneGrid = data.frame(nvmax = 1:21))
#step.model1$results
#step.model1$bestTune
summary(step.model1$finalModel)
#coef(step.model1$finalModel, 5)
#model.lm2 <- lm(hapiscore_whr~aged_15plus_unemployment_rate_percent+hdiindex+foodinsecurity+vaccine+incomeperperson, #data=df_variables_imputed)
#summary(model.lm2)
#AIC_calculated <- 2*7 + 241* (log( 2*3.14* (1-0.759)*24962/241 ) + 1)
#AIC_calculated
set.seed(123)
# Set up repeated k-fold cross-validation
#Train the model
step.model1 <- train(hapiscore_whr ~., data = df_variables_full,
method = "leapBackward",
trControl = train.control,
tuneGrid = data.frame(nvmax = 1:21))
step.model1$results
step.model1$bestTune
summary(step.model1$finalModel)
model.lm2 <- lm(hapiscore_whr~aged_15plus_unemployment_rate_percent+hdiindex+foodinsecurity+vaccine+incomeperperson, data=df_variables_full)
#summary(model.lm2)
#AIC_calculated <- 2*7 + 241* (log( 2*3.14* (1-0.759)*24962/241 ) + 1)
#AIC_calculated
par(mfrow=c(5,4))
for(i in colnames(df_variables)) {
hist = boxplot(na.omit(df_variables[[i]]), breaks = 20, main = paste("Distribution of", i),xlab=NULL)
}
par(mfrow=c(6,3))
for(i in colnames(df_variables)) {
hist = boxplot(na.omit(df_variables[[i]]), breaks = 20, main = paste("Distribution of", i),xlab=NULL)
}
par(mfrow=c(7,2))
for(i in colnames(df_variables)) {
hist = boxplot(na.omit(df_variables[[i]]), breaks = 20, main = paste("Distribution of", i),xlab=NULL)
}
set.seed(123)
# Set up repeated k-fold cross-validation
#Train the model
step.model1 <- train(hapiscore_whr ~parliament+aged_15plus_unemployment_rate_percent+right+sanitation+edu+internetusers+sdi+hdiindex+forestcoverage+
militaryexpenditure+mortality+wateraccess+broadband+agriculture+debt+gdppercapita_growth+foodinsecurity+
exports+corruption+vaccine+incomeperperson, data = df_variables_full,
method = "leapBackward",
trControl = train.control,
tuneGrid = data.frame(nvmax = 1:21))
#step.model1$results
#step.model1$bestTune
summary(step.model1$finalModel)
model.lm2 <- lm(hapiscore_whr~aged_15plus_unemployment_rate_percent+hdiindex+foodinsecurity+vaccine+incomeperperson, data=df_variables_full)
summary(model.lm2)
#AIC_calculated <- 2*7 + 241* (log( 2*3.14* (1-0.759)*24962/241 ) + 1)
#AIC_calculated
set.seed(123)
# Set up repeated k-fold cross-validation
#Train the model
step.model1 <- train(hapiscore_whr ~parliament+aged_15plus_unemployment_rate_percent+right+sanitation+edu+internetusers+sdi+hdiindex+forestcoverage+
militaryexpenditure+mortality+wateraccess+broadband+agriculture+debt+gdppercapita_growth+foodinsecurity+
exports+corruption+vaccine+incomeperperson, data = df_variables_full,
method = "leapBackward",
trControl = train.control,
tuneGrid = data.frame(nvmax = 1:21))
step.model1$results
#step.model1$bestTune
#summary(step.model1$finalModel)
model.lm2 <- lm(hapiscore_whr~aged_15plus_unemployment_rate_percent+hdiindex+foodinsecurity+vaccine+incomeperperson, data=df_variables_full)
summary(model.lm2)
#AIC_calculated <- 2*7 + 241* (log( 2*3.14* (1-0.759)*24962/241 ) + 1)
#AIC_calculated
set.seed(123)
# Set up repeated k-fold cross-validation
#Train the model
step.model1 <- train(hapiscore_whr ~parliament+aged_15plus_unemployment_rate_percent+right+sanitation+edu+internetusers+sdi+hdiindex+forestcoverage+
militaryexpenditure+mortality+wateraccess+broadband+agriculture+debt+gdppercapita_growth+foodinsecurity+
exports+corruption+vaccine+incomeperperson, data = df_variables_full,
method = "leapBackward",
trControl = train.control,
tuneGrid = data.frame(nvmax = 1:21))
#step.model1$results
step.model1$bestTune
#summary(step.model1$finalModel)
model.lm2 <- lm(hapiscore_whr~aged_15plus_unemployment_rate_percent+hdiindex+foodinsecurity+vaccine+incomeperperson, data=df_variables_full)
summary(model.lm2)
#AIC_calculated <- 2*7 + 241* (log( 2*3.14* (1-0.759)*24962/241 ) + 1)
#AIC_calculated
knitr::opts_chunk$set(echo = TRUE,warning=FALSE,message=FALSE,fig.width=10)
library(tidyverse)
library(GGally)
library(ggplot2)
library(caret)
library(MASS)
df=readRDS("./merged_gapminder_happiness.rds")
df_variables=df%>%dplyr::select(-country,-year)
par(mfrow=c(1,2))
hist(na.omit(df_variables$hapiscore_whr),main="Histogram of happiness score",xlab="Happiness score")
boxplot(na.omit(df_variables$hapiscore_whr),main="Boxplot of happiness score",ylab="Hapiness score")
summary(na.omit(df_variables$hapiscore_whr))
par(mfrow=c(4,5))
for(i in colnames(df_variables)) {
hist = boxplot(na.omit(df_variables[[i]]), breaks = 20, main = paste("Distribution of", i),xlab=NULL)
}
library(VIM)
df_variables_imputed=kNN(df_variables%>%dplyr::select(-hapiscore_whr),k=10,imp_var=F)
df_variables_imputed['hapiscore_whr']=df_variables$hapiscore_whr
ggcorr(df_variables%>%dplyr::select(-hapiscore_whr,-foodinsecurity,-aged_15plus_unemployment_rate_percent),geom="circle",layout.exp = 1)+ggtitle("Before imputation")
ggcorr(df_variables_imputed%>%dplyr::select(-hapiscore_whr,-foodinsecurity,-aged_15plus_unemployment_rate_percent),geom="circle",layout.exp = 1)+ggtitle("After imputation")
ggcorr(df_variables_imputed%>%dplyr::select(-hapiscore_whr),geom="circle",layout.exp = 1)+ggtitle("Full correlation matrix after imputation")
lm_independent=lm(hapiscore_whr~gdppercapita_growth+forestcoverage+sdi+aged_15plus_unemployment_rate_percent+parliament+vaccine,data=df_variables_imputed)
summary(lm_independent)
car::vif(lm_independent)
df_variables_remaining=df_variables_imputed%>%dplyr::select(-gdppercapita_growth,-forestcoverage,-sdi,-aged_15plus_unemployment_rate_percent,-parliament,-hapiscore_whr,-vaccine)
pr_happiness=prcomp(df_variables_remaining,scale=T,center=T)
pr_var=pr_happiness$sdev^2
prop_var=pr_var/sum(pr_var)
plot(cumsum(prop_var),xlab="Number of PCs",ylab="Cumulative proportion of total variance")
pr_pc=pr_happiness$x[,1:4]
pr_pc=cbind(pr_pc,df_variables_imputed%>%dplyr::select(sdi,parliament))
pr_pc['hapiscore_whr']=df_variables$hapiscore_whr
# Pure PCR regression
model_pure_pcr=lm(hapiscore_whr~PC1+PC2+PC3+PC4,data=pr_pc)
# PCR + selected independent variables
model_pcr_additive=lm(hapiscore_whr~PC1+PC2+PC3+PC4+sdi+parliament,data=pr_pc)
summary(model_pcr_additive)
anova(model_pure_pcr,model_pcr_additive,test="F")
model_3_pcr=lm(hapiscore_whr~PC1+PC2+PC3,data=pr_pc)
par(mfrow=c(1,2))
plot(model_pure_pcr,which=c(1))
plot(model_pure_pcr,which=c(2))
na_criteria=is.na(df_variables_imputed$hapiscore_whr)
working_pr=pr_pc[!na_criteria,]
# Constructing our 10-fold cross validation of the 3 PC regression
set.seed(123)
lm_model_final_cv=train(hapiscore_whr~PC1+PC2+PC3,
method="lm",
data=working_pr,
trControl=trainControl(method="cv",number=10))
predictions_cv=predict(lm_model_final_cv)
predictions=predict(model_3_pcr)
ggplot(data=NULL)+
geom_density(aes(x=working_pr$hapiscore_whr,color="Actual happiness score"))+
geom_density(aes(x=predictions_cv,color="Predicted happiness score from CV"))+
theme_bw()+xlab("Happiness score")
# df_variables_full is df_variables_imputed, but only for observations that do not have NULL for hapiness scores. This is necessary as caret does not tolerate missing values for its target variables unlike lm
df_variables_full=df_variables_imputed%>%filter(!is.na(hapiscore_whr))
train.control <- trainControl(method = "cv", number = 10)
res.lm <- lm(hapiscore_whr ~., data = df_variables_full)
# Train the model
set.seed(123)
step.model <- train(hapiscore_whr ~., data = df_variables_full,
method = "lmStepAIC",
trControl = train.control,
trace = FALSE
)
summary(step.model$finalModel)
set.seed(123)
# Set up repeated k-fold cross-validation
#Train the model
step.model1 <- train(hapiscore_whr ~parliament+aged_15plus_unemployment_rate_percent+right+sanitation+edu+internetusers+sdi+hdiindex+forestcoverage+
militaryexpenditure+mortality+wateraccess+broadband+agriculture+debt+gdppercapita_growth+foodinsecurity+
exports+corruption+vaccine+incomeperperson, data = df_variables_full,
method = "leapBackward",
trControl = train.control,
tuneGrid = data.frame(nvmax = 1:21))
#step.model1$results
step.model1$bestTune
#summary(step.model1$finalModel)
model.lm2 <- lm(hapiscore_whr~aged_15plus_unemployment_rate_percent+hdiindex+foodinsecurity+vaccine+incomeperperson, data=df_variables_full)
summary(model.lm2)
AIC(model.lm2)
#AIC_calculated <- 2*7 + 241* (log( 2*3.14* (1-0.759)*24962/241 ) + 1)
#AIC_calculated
set.seed(123)
# Set up repeated k-fold cross-validation
#Train the model
step.model1 <- train(hapiscore_whr ~parliament+aged_15plus_unemployment_rate_percent+right+sanitation+edu+internetusers+sdi+hdiindex+forestcoverage+
militaryexpenditure+mortality+wateraccess+broadband+agriculture+debt+gdppercapita_growth+foodinsecurity+
exports+corruption+vaccine+incomeperperson, data = df_variables_full,
method = "leapBackward",
trControl = train.control,
tuneGrid = data.frame(nvmax = 1:21))
#step.model1$results
step.model1$bestTune
#summary(step.model1$finalModel)
model.lm2 <- lm(hapiscore_whr~aged_15plus_unemployment_rate_percent+hdiindex+foodinsecurity+vaccine+incomeperperson, data=df_variables_full)
summary(model.lm2)
AIC(model.lm2)
AIC_calculated <- 2*7 + 241* (log( 2*3.14* (1-0.759)*24962/241 ) + 1)
AIC_calculated
set.seed(123)
# Set up repeated k-fold cross-validation
#Train the model
step.model1 <- train(hapiscore_whr ~parliament+aged_15plus_unemployment_rate_percent+right+sanitation+edu+internetusers+sdi+hdiindex+forestcoverage+
militaryexpenditure+mortality+wateraccess+broadband+agriculture+debt+gdppercapita_growth+foodinsecurity+
exports+corruption+vaccine+incomeperperson, data = df_variables_imputed,
method = "leapBackward",
trControl = train.control,
tuneGrid = data.frame(nvmax = 1:21))
# Set seed for reproducibility
set.seed(123)
# Set up repeated k-fold cross-validation
train.control <- trainControl(method = "cv", number = 10)
# Train the model
step.model1 <- train(hapiscore_whr ~parliament+aged_15plus_unemployment_rate_percent+right+sanitation+edu+internetusers+sdi+hdiindex+forestcoverage+
militaryexpenditure+mortality+wateraccess+broadband+agriculture+debt+gdppercapita_growth+foodinsecurity+
exports+corruption+vaccine+incomeperperson, data = df_variables_imputed,
method = "leapBackward",
tuneGrid = data.frame(nvmax = 1:21),
trControl = train.control
)
# Set seed for reproducibility
set.seed(123)
# Set up repeated k-fold cross-validation
train.control <- trainControl(method = "cv", number = 10)
# Train the model
step.model1 <- train(hapiscore_whr ~parliament+aged_15plus_unemployment_rate_percent+right+sanitation+edu+internetusers+sdi+hdiindex+forestcoverage+
militaryexpenditure+mortality+wateraccess+broadband+agriculture+debt+gdppercapita_growth+foodinsecurity+
exports+corruption+vaccine+incomeperperson, data = df_variables_full,
method = "leapBackward",
tuneGrid = data.frame(nvmax = 1:21),
trControl = train.control
)
step.model1$results
step.model1$bestTune
summary(step.model1$finalModel)
coef(step.model1$finalModel, 5)
knitr::opts_chunk$set(echo = TRUE,warning=FALSE,message=FALSE,fig.width=10)
library(tidyverse)
library(GGally)
library(ggplot2)
library(caret)
library(MASS)
df=readRDS("./merged_gapminder_happiness.rds")
df_variables=df%>%dplyr::select(-country,-year)
par(mfrow=c(1,2))
hist(na.omit(df_variables$hapiscore_whr),main="Histogram of happiness score",xlab="Happiness score")
boxplot(na.omit(df_variables$hapiscore_whr),main="Boxplot of happiness score",ylab="Hapiness score")
summary(na.omit(df_variables$hapiscore_whr))
par(mfrow=c(4,5))
for(i in colnames(df_variables)) {
hist = boxplot(na.omit(df_variables[[i]]), breaks = 20, main = paste("Distribution of", i),xlab=NULL)
}
library(VIM)
df_variables_imputed=kNN(df_variables%>%dplyr::select(-hapiscore_whr),k=10,imp_var=F)
df_variables_imputed['hapiscore_whr']=df_variables$hapiscore_whr
ggcorr(df_variables%>%dplyr::select(-hapiscore_whr,-foodinsecurity,-aged_15plus_unemployment_rate_percent),geom="circle",layout.exp = 1)+ggtitle("Before imputation")
ggcorr(df_variables_imputed%>%dplyr::select(-hapiscore_whr,-foodinsecurity,-aged_15plus_unemployment_rate_percent),geom="circle",layout.exp = 1)+ggtitle("After imputation")
ggcorr(df_variables_imputed%>%dplyr::select(-hapiscore_whr),geom="circle",layout.exp = 1)+ggtitle("Full correlation matrix after imputation")
lm_independent=lm(hapiscore_whr~gdppercapita_growth+forestcoverage+sdi+aged_15plus_unemployment_rate_percent+parliament+vaccine,data=df_variables_imputed)
summary(lm_independent)
car::vif(lm_independent)
df_variables_remaining=df_variables_imputed%>%dplyr::select(-gdppercapita_growth,-forestcoverage,-sdi,-aged_15plus_unemployment_rate_percent,-parliament,-hapiscore_whr,-vaccine)
pr_happiness=prcomp(df_variables_remaining,scale=T,center=T)
pr_var=pr_happiness$sdev^2
prop_var=pr_var/sum(pr_var)
plot(cumsum(prop_var),xlab="Number of PCs",ylab="Cumulative proportion of total variance")
pr_pc=pr_happiness$x[,1:4]
pr_pc=cbind(pr_pc,df_variables_imputed%>%dplyr::select(sdi,parliament))
pr_pc['hapiscore_whr']=df_variables$hapiscore_whr
# Pure PCR regression
model_pure_pcr=lm(hapiscore_whr~PC1+PC2+PC3+PC4,data=pr_pc)
# PCR + selected independent variables
model_pcr_additive=lm(hapiscore_whr~PC1+PC2+PC3+PC4+sdi+parliament,data=pr_pc)
summary(model_pcr_additive)
anova(model_pure_pcr,model_pcr_additive,test="F")
model_3_pcr=lm(hapiscore_whr~PC1+PC2+PC3,data=pr_pc)
par(mfrow=c(1,2))
plot(model_pure_pcr,which=c(1))
plot(model_pure_pcr,which=c(2))
na_criteria=is.na(df_variables_imputed$hapiscore_whr)
working_pr=pr_pc[!na_criteria,]
# Constructing our 10-fold cross validation of the 3 PC regression
set.seed(123)
lm_model_final_cv=train(hapiscore_whr~PC1+PC2+PC3,
method="lm",
data=working_pr,
trControl=trainControl(method="cv",number=10))
predictions_cv=predict(lm_model_final_cv)
predictions=predict(model_3_pcr)
ggplot(data=NULL)+
geom_density(aes(x=working_pr$hapiscore_whr,color="Actual happiness score"))+
geom_density(aes(x=predictions_cv,color="Predicted happiness score from CV"))+
theme_bw()+xlab("Happiness score")
# df_variables_full is df_variables_imputed, but only for observations that do not have NULL for hapiness scores. This is necessary as caret does not tolerate missing values for its target variables unlike lm
df_variables_full=df_variables_imputed%>%filter(!is.na(hapiscore_whr))
train.control <- trainControl(method = "cv", number = 10)
res.lm <- lm(hapiscore_whr ~., data = df_variables_full)
# Train the model
set.seed(123)
step.model <- train(hapiscore_whr ~., data = df_variables_full,
method = "lmStepAIC",
trControl = train.control,
trace = FALSE
)
step.model$results
summary(step.model$finalModel)
AIC(step.model$finalModel)
# df_variables_full is df_variables_imputed, but only for observations that do not have NULL for hapiness scores. This is necessary as caret does not tolerate missing values for its target variables unlike lm
df_variables_full=df_variables_imputed%>%filter(!is.na(hapiscore_whr))
train.control <- trainControl(method = "cv", number = 10)
res.lm <- lm(hapiscore_whr ~., data = df_variables_full)
# Train the model
set.seed(123)
step.model <- train(hapiscore_whr ~., data = df_variables_full,
method = "lmStepAIC",
trControl = train.control,
trace = FALSE
)
step.model$results
summary(step.model$finalModel)
VIF(step.model$finalModel)
# df_variables_full is df_variables_imputed, but only for observations that do not have NULL for hapiness scores. This is necessary as caret does not tolerate missing values for its target variables unlike lm
df_variables_full=df_variables_imputed%>%filter(!is.na(hapiscore_whr))
train.control <- trainControl(method = "cv", number = 10)
res.lm <- lm(hapiscore_whr ~., data = df_variables_full)
# Train the model
set.seed(123)
step.model <- train(hapiscore_whr ~., data = df_variables_full,
method = "lmStepAIC",
trControl = train.control,
trace = FALSE
)
step.model$results
summary(step.model$finalModel)
car::vif(step.model$finalModel)
set.seed(123)
# Set up repeated k-fold cross-validation
#Train the model
step.model1 <- train(hapiscore_whr ~parliament+aged_15plus_unemployment_rate_percent+right+sanitation+edu+internetusers+sdi+hdiindex+forestcoverage+
militaryexpenditure+mortality+wateraccess+broadband+agriculture+debt+gdppercapita_growth+foodinsecurity+
exports+corruption+vaccine+incomeperperson, data = df_variables_full,
method = "leapBackward",
trControl = train.control,
tuneGrid = data.frame(nvmax = 1:21))
step.model1$results
step.model1$bestTune
#summary(step.model1$finalModel)
model.lm2 <- lm(hapiscore_whr~aged_15plus_unemployment_rate_percent+hdiindex, data=df_variables_full)
summary(model.lm2)
AIC(model.lm2)
car::vif(model.lm2)
set.seed(123)
# Set up repeated k-fold cross-validation
#Train the model
step.model1 <- train(hapiscore_whr ~parliament+aged_15plus_unemployment_rate_percent+right+sanitation+edu+internetusers+sdi+hdiindex+forestcoverage+
militaryexpenditure+mortality+wateraccess+broadband+agriculture+debt+gdppercapita_growth+foodinsecurity+
exports+corruption+vaccine+incomeperperson, data = df_variables_full,
method = "leapBackward",
trControl = train.control,
tuneGrid = data.frame(nvmax = 1:21))
step.model1$results
step.model1$bestTune
#summary(step.model1$finalModel)
model.lm2 <- lm(hapiscore_whr~aged_15plus_unemployment_rate_percent+hdiindex, data=df_variables_full)
summary(model.lm2)
print("Model VIF:")
car::vif(model.lm2)
test=summary(model.lm2)
test$adj.r.squared
test$residuals
model_name=c("CV 3 PCR","CV StepAIC","CV Backward selection")
aic_values=c(AIC(lm_model_final_cv),AIC(step.model$finalModel),AIC(model.lm2))
summary(lm_model_final_cv)
summary(lm_model_final_cv)$AIC
AIC(lm_model_final_cv)
extractAIC(lm_model_final_cv)
model_name=c("CV 3 PCR","CV StepAIC","CV Backward selection")
adj_r_squared=c(summary(lm_model_final_cv)$adj.r.squared,summary(step.model$finalModel)$adj.r.squared,summary(model.lm2)$adj.r.squared)
rmse_model=c(RMSE(fitted(lm_model_final_cv),df_variables_full$hapiscore_whr),
RMSE(fitted(step.model$finalModel),df_variables_full$hapiscore_whr),
RMSE(fitted(model.lm2),df_variables_full$hapiscore_whr))
rmse_model
final_compare=data.frame(model_name=model_name,adj_r_squared=adj_r_squared,rmse_model=rmse_model)
final_compare
final_compare=data.frame(model_name=model_name,adj_r_squared=adj_r_squared,rmse=rmse_model)
final_compare=data.frame(model_name=model_name,adj_r_squared=adj_r_squared,rmse=rmse_model)
final_compare%>%spread("model_name")
final_compare=data.frame(model_name=model_name,adj_r_squared=adj_r_squared,rmse=rmse_model)
final_compare%>%pivot_longer(c("adj_r_squared","rmse_model"))
final_compare=data.frame(model_name=model_name,adj_r_squared=adj_r_squared,rmse=rmse_model)
final_compare%>%pivot_longer(c("adj_r_squared","rmse"))
final_compare=data.frame(model_name=model_name,adj_r_squared=adj_r_squared,rmse=rmse_model)
final_compare%>%pivot_longer(c("adj_r_squared","rmse"))%>%pivot_wider(names_from=model_name,values_from=value)
library(tidyverse)
library(GGally)
library(ggplot2)
library(caret)
library(MASS)
pr_pc
# Constructing our 10-fold cross validation of the 3 PC regression
set.seed(123)
lm_model_final_cv=train(hapiscore_whr~PC1+PC2+PC3,
method="lm",
data=pc_pr,
trControl=trainControl(method="cv",number=10))
# Constructing our 10-fold cross validation of the 3 PC regression
set.seed(123)
lm_model_final_cv=train(hapiscore_whr~PC1+PC2+PC3,
method="lm",
data=pr_pc,
trControl=trainControl(method="cv",number=10))
pr_pc%>%filter(!is.na(hapiscore_whr))
df_variables_full=df_variables_imputed%>%filter(!is.na(hapiscore_whr))
# Constructing our 10-fold cross validation of the 3 PC regression
set.seed(123)
lm_model_final_cv=train(hapiscore_whr~PC1+PC2+PC3,
method="lm",
data=working_pc,
trControl=trainControl(method="cv",number=10))
working_pc=pr_pc%>%filter(!is.na(hapiscore_whr))
df_variables_full=df_variables_imputed%>%filter(!is.na(hapiscore_whr))
# Constructing our 10-fold cross validation of the 3 PC regression
set.seed(123)
lm_model_final_cv=train(hapiscore_whr~PC1+PC2+PC3,
method="lm",
data=working_pc,
trControl=trainControl(method="cv",number=10))
ggplot(data=NULL)+
geom_density(aes(x=working_pc$hapiscore_whr,color="Actual happiness score"))+
geom_density(aes(x=predictions_cv,color="Predicted happiness score from CV"))+
theme_bw()+xlab("Happiness score")
ggcorr(df_variables_imputed%>%dplyr::select(-hapiscore_whr),geom="circle",layout.exp = 2)+ggtitle("Full correlation matrix after imputation")
ggcorr(df_variables_imputed%>%dplyr::select(-hapiscore_whr),geom="circle",layout.exp = 5)+ggtitle("Full correlation matrix after imputation")
ggcorr(df_variables_imputed%>%dplyr::select(-hapiscore_whr),geom="circle",layout.exp = 10)+ggtitle("Full correlation matrix after imputation")
library(factoextra)
library(factoextra)
fviz_contrib(pr_happiness,choice="var",axes=1)
library(factoextra)
fviz_contrib(pr_happiness,choice="var",axes=1)
library(factoextra)
fviz_contrib(pr_happiness,choice="var",axes=2)
library(factoextra)
fviz_contrib(pr_happiness,choice="var",axes=1)
model_k=lm(hapiscore_whr~hdiindex+internetusers+foodinsecurity,data=df_variables_full)
model_k
summary(model_k)
vif(hdiindex)
car::vif(model_k)
qplot(hdiindex,hapiscore_whr,df_variables_full,geom="scatter")
qplot(hdiindex,hapiscore_whr,df_variables_full,geom="scatterplot")
qplot(hdiindex,hapiscore_whr,df_variables_full,geom="point")
qplot(x=hdiindex,y=hapiscore_whr,data=df_variables_full,geom="scatter")
ggplot(df_variables_full,aes(x=hdiindex,y=hapiscore_whr))+geom_scatter()
ggplot(df_variables_full,aes(x=hdiindex,y=hapiscore_whr))+geom_point()
ggplot(df_variables_full,aes(x=hdiindex,y=hapiscore_whr))+geom_point()+theme_bw()
ggplot(df_variables_full,aes(x=hdiindex,y=hapiscore_whr))+geom_point()+theme_bw()+labs(x="HDI Index","Happiness score")+ggtitle("Happiness score against HDI")+theme(panel.grid.major = element_blank())
ggplot(df_variables_full,aes(x=hdiindex,y=hapiscore_whr))+geom_point()+theme_bw()+labs(x="HDI Index","Happiness score")+ggtitle("Happiness score against HDI")+theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank())
ggplot(df_variables_full,aes(x=hdiindex,y=hapiscore_whr))+geom_point()+theme_bw()+labs(x="HDI Index",y="Happiness score")+ggtitle("Happiness score against HDI")+theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank())
par(mfrow=c(4,5))
for(i in colnames(df_variables)) {
hist = boxplot(na.omit(df_variables[[i]]), breaks = 20, main = paste("Distribution of", i),xlab=NULL)
}
par(mfrow=c(4,5))
for(i in colnames(df_variables)) {
hist = boxplot(na.omit(df_variables[[i]]), breaks = 20, main = paste("Distribution of", i),xlab=NULL)
}
par(mfrow=c(5,4))
for(i in colnames(df_variables)) {
hist = boxplot(na.omit(df_variables[[i]]), breaks = 20, main = paste("Distribution of", i),xlab=NULL)
}
par(mfrow=c(7,3))
for(i in colnames(df_variables)) {
hist = boxplot(na.omit(df_variables[[i]]), breaks = 20, main = paste("Distribution of", i),xlab=NULL)
}
par(mfrow=c(7,3))
for(i in colnames(df_variables)) {
hist = boxplot(na.omit(df_variables[[i]]), breaks = 20, main = paste("Distribution of", i),xlab=NULL)
}
par(mfrow=c(5,4))
for(i in colnames(df_variables)) {
hist = boxplot(na.omit(df_variables[[i]]), breaks = 20, main = paste("Distribution of", i),xlab=NULL)
}
par(mfrow=c(5,4))
for(i in colnames(df_variables)) {
hist = boxplot(na.omit(df_variables[[i]]), breaks = 20, main = paste("Distribution of", i),xlab=NULL)
}
par(mfrow=c(5,4))
for(i in colnames(df_variables)) {
hist = boxplot(na.omit(df_variables[[i]]), breaks = 20, main = paste("Distribution of", i),xlab=NULL)
}
par(mfrow=c(4,5))
for(i in colnames(df_variables)) {
hist = boxplot(na.omit(df_variables[[i]]), breaks = 20, main = paste("Distribution of", i),xlab=NULL)
}
par(mfrow=c(4,6))
for(i in colnames(df_variables)) {
hist = boxplot(na.omit(df_variables[[i]]), breaks = 20, main = paste("Distribution of", i),xlab=NULL)
}
test=c(0.5*(sin(1)-cos(1)),-0.5*(sin(1)),0.5*sin(1),-0.5*(sin(1)+cos(1)))
mat=matrix(test,byrow=T,nrow=2)
mat
test=c(0.5*(sin(1)-cos(1)),-0.5*(sin(1)),0.5*sin(1),-0.5*(sin(1)+cos(1)))
mat=matrix(test,byrow=T,nrow=2)
mat_results=matrix(c(1-cos(1)-sin(1),1+sin(1)-cos(1)),byrow=F,ncol=1)
mat_results
test=c(0.5*(sin(1)-cos(1)),-0.5*(sin(1)),0.5*sin(1),-0.5*(sin(1)+cos(1)))
mat=matrix(test,byrow=T,nrow=2)
mat_results=matrix(c(1-cos(1)-sin(1),1+sin(1)-cos(1)),byrow=F,ncol=1)
solve(mat)%*%mat_results
